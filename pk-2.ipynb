{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1748b2c",
   "metadata": {},
   "source": [
    "#  Рубежный контроль №2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2fd5ac",
   "metadata": {},
   "source": [
    "### Выполнил: Ма Линь"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cbf3a0",
   "metadata": {},
   "source": [
    "### Студент группы:ИУ5И-21М "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daea34a2",
   "metadata": {},
   "source": [
    "## Тема: Методы обработки текстов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7065f2",
   "metadata": {},
   "source": [
    "   Необходимо решить задачу классификации текстов на основе любого выбранного Вами датасета (кроме примера, который рассматривался в лекции). Классификация может быть бинарной или многоклассовой. Целевой признак из выбранного Вами датасета может иметь любой физический смысл, примером является задача анализа тональности текста."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bab5415",
   "metadata": {},
   "source": [
    "Необходимо сформировать два варианта векторизации признаков - на основе CountVectorizer и на основе TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69294549",
   "metadata": {},
   "source": [
    "В качестве классификаторов необходимо использовать два классификатора по варианту для Вашей группы:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db338e0",
   "metadata": {},
   "source": [
    "### Мой вариант:   LogisticRegression   &   Multinomial Naive Bayes - MNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffceb8b",
   "metadata": {},
   "source": [
    "#  Список Библитека:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ea9e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Tuple\n",
    "from scipy import stats\n",
    "from IPython.display import Image\n",
    "from sklearn.datasets import load_iris, load_boston\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, median_absolute_error, r2_score \n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC, OneClassSVM, SVR, NuSVR, LinearSVR\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "sns.set(style=\"ticks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cda8f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Tuple\n",
    "from scipy import stats\n",
    "from IPython.display import Image\n",
    "from sklearn.datasets import load_iris, load_boston\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, median_absolute_error, r2_score \n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC, OneClassSVM, SVR, NuSVR, LinearSVR\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "sns.set(style=\"ticks\")\n",
    "def accuracy_score_for_classes(\n",
    "    y_true: np.ndarray, \n",
    "    y_pred: np.ndarray) -> Dict[int, float]:\n",
    "    \"\"\"\n",
    "    Вычисление метрики accuracy для каждого класса\n",
    "    y_true - истинные значения классов\n",
    "    y_pred - предсказанные значения классов\n",
    "    Возвращает словарь: ключ - метка класса, \n",
    "    значение - Accuracy для данного класса\n",
    "    \"\"\"\n",
    "    # Для удобства фильтрации сформируем Pandas DataFrame \n",
    "    d = {'t': y_true, 'p': y_pred}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    # Метки классов\n",
    "    classes = np.unique(y_true)\n",
    "    # Результирующий словарь\n",
    "    res = dict()\n",
    "    # Перебор меток классов\n",
    "    for c in classes:\n",
    "        # отфильтруем данные, которые соответствуют \n",
    "        # текущей метке класса в истинных значениях\n",
    "        temp_data_flt = df[df['t']==c]\n",
    "        # расчет accuracy для заданной метки класса\n",
    "        temp_acc = accuracy_score(\n",
    "            temp_data_flt['t'].values, \n",
    "            temp_data_flt['p'].values)\n",
    "        # сохранение результата в словарь\n",
    "        res[c] = temp_acc\n",
    "    return res\n",
    "\n",
    "def print_accuracy_score_for_classes(\n",
    "    y_true: np.ndarray, \n",
    "    y_pred: np.ndarray):\n",
    "    \"\"\"\n",
    "    Вывод метрики accuracy для каждого класса\n",
    "    \"\"\"\n",
    "    accs = accuracy_score_for_classes(y_true, y_pred)\n",
    "    if len(accs)>0:\n",
    "        print('Метка \\t Accuracy')\n",
    "    for i in accs:\n",
    "        print('{} \\t {}'.format(i, accs[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57f4952",
   "metadata": {},
   "source": [
    "# Загрузка данных\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5798159",
   "metadata": {},
   "source": [
    "scotch_review.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d24010d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>review.point</th>\n",
       "      <th>price</th>\n",
       "      <th>currency</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Johnnie Walker Blue Label, 40%</td>\n",
       "      <td>Blended Scotch Whisky</td>\n",
       "      <td>97</td>\n",
       "      <td>225</td>\n",
       "      <td>$</td>\n",
       "      <td>Magnificently powerful and intense. Caramels, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Black Bowmore, 1964 vintage, 42 year old, 40.5%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>97</td>\n",
       "      <td>4500.00</td>\n",
       "      <td>$</td>\n",
       "      <td>What impresses me most is how this whisky evol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bowmore 46 year old (distilled 1964), 42.9%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>97</td>\n",
       "      <td>13500.00</td>\n",
       "      <td>$</td>\n",
       "      <td>There have been some legendary Bowmores from t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Compass Box The General, 53.4%</td>\n",
       "      <td>Blended Malt Scotch Whisky</td>\n",
       "      <td>96</td>\n",
       "      <td>325</td>\n",
       "      <td>$</td>\n",
       "      <td>With a name inspired by a 1926 Buster Keaton m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Chivas Regal Ultis, 40%</td>\n",
       "      <td>Blended Malt Scotch Whisky</td>\n",
       "      <td>96</td>\n",
       "      <td>160</td>\n",
       "      <td>$</td>\n",
       "      <td>Captivating, enticing, and wonderfully charmin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             name  \\\n",
       "0           1                   Johnnie Walker Blue Label, 40%   \n",
       "1           2  Black Bowmore, 1964 vintage, 42 year old, 40.5%   \n",
       "2           3      Bowmore 46 year old (distilled 1964), 42.9%   \n",
       "3           4                   Compass Box The General, 53.4%   \n",
       "4           5                          Chivas Regal Ultis, 40%   \n",
       "\n",
       "                     category  review.point     price currency  \\\n",
       "0       Blended Scotch Whisky            97       225        $   \n",
       "1          Single Malt Scotch            97   4500.00        $   \n",
       "2          Single Malt Scotch            97  13500.00        $   \n",
       "3  Blended Malt Scotch Whisky            96       325        $   \n",
       "4  Blended Malt Scotch Whisky            96       160        $   \n",
       "\n",
       "                                         description  \n",
       "0  Magnificently powerful and intense. Caramels, ...  \n",
       "1  What impresses me most is how this whisky evol...  \n",
       "2  There have been some legendary Bowmores from t...  \n",
       "3  With a name inspired by a 1926 Buster Keaton m...  \n",
       "4  Captivating, enticing, and wonderfully charmin...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML_rev = pd.read_csv(\"scotch_review.csv\")\n",
    "ML_rev.head()\n",
    "#WC_df = pd.read_csv(\"WClothing_Reviews.csv\", delimiter='\\t', header=None, names=['text', 'value'])\n",
    "#WC_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8cb8d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2247, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML_rev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed148ec1",
   "metadata": {},
   "source": [
    "Держать колонки \"Review Text\" и \"Recommended IND\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfc4595f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Magnificently powerful and intense. Caramels, ...</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What impresses me most is how this whisky evol...</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There have been some legendary Bowmores from t...</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>With a name inspired by a 1926 Buster Keaton m...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Captivating, enticing, and wonderfully charmin...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  value\n",
       "0  Magnificently powerful and intense. Caramels, ...     97\n",
       "1  What impresses me most is how this whisky evol...     97\n",
       "2  There have been some legendary Bowmores from t...     97\n",
       "3  With a name inspired by a 1926 Buster Keaton m...     96\n",
       "4  Captivating, enticing, and wonderfully charmin...     96"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML_df = pd.DataFrame(ML_rev,columns=['description','review.point'])\n",
    "ML_df.columns = ['text','value']\n",
    "ML_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36148058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"What impresses me most is how this whisky evolves; it's incredibly complex. On the nose and palate, this is a thick, viscous, whisky with notes of sticky toffee, earthy oak, fig cake, roasted nuts, fallen fruit, pancake batter, black cherry, ripe peach, dark chocolate-covered espresso bean, polished leather, tobacco, a hint of wild game, and lingering, leafy damp kiln smoke. Flavors continue on the palate long after swallowing. This is what we all hope for (and dream of) in an older whisky!\",\n",
       " \"There have been some legendary Bowmores from the mid-60s and this is every bit their equal. All of them share a remarkable aroma of tropical fruit, which here moves into hallucinatory intensity: guava, mango, peach, pineapple, grapefruit. There’s a very light touch of peat smoke, more a memory of Islay than the reality. Concentrated; even at low strength the palate is silky, heady, and haunting, and lasts forever in the dry glass. A legend is born. (Eight bottles only for the U.S.) Editor's Choice.\",\n",
       " \"With a name inspired by a 1926 Buster Keaton movie, only 1,698 bottles produced, and the news that one of the two batches is more than 30 years old, the clues were there that this blend was never going to be cheap. It isn't, but it's superb, rich in flavor that screams dusty old oak office, fresh polish, and Sunday church, with spices, oak dried fruits, squiggly raisins, and a surprising melting fruit-and-nut dairy chocolate back story.\",\n",
       " \"Captivating, enticing, and wonderfully charming, this first blended malt from Chivas Regal contains selections of five Speyside malts: Strathisla, Longmorn, Tormore, Allt-a-Bhainne, and Braeval. Red apple, cherry, raspberry fudge, peach and mango fruit salad, dusting of cinnamon, and dry heather sprigs. In essence, it’s rich and satisfying, with dark vanilla, apricot, Bourneville-covered Brazil nuts, and tangerine, smoothed over by caramel and wood spices, maltiness, and gingersnap biscuits. Quite heavenly. Editor's Choice\",\n",
       " 'Powerful, muscular, well-textured, and invigorating. Even within the realm of Ardbeg, this one stands out. The more aggressive notes of coal tar, damp kiln, anise, and smoked seaweed are supported by an array of fruit (black raspberry, black cherry, plum), dark chocolate, espresso, molasses, bacon fat, kalamata olive, and warming cinnamon on the finish. Quite stunning!',\n",
       " 'Deep gold color. Surprisingly lively on the nose for its age. A complex array of fruit (tangerine, sultana, pink grapefruit, papaya, and the general overall citrus DNA that you’ll find in old Bowmores), with balancing notes of honey and vanilla. A hint of damp smoke and coconut. Just like with Black Bowmore, this is a texturally soothing whisky on the palate, which continues to evolve in waves -- first the sweet honey, coating vanilla, and lively fruit, then turning quite visceral, with juicy oak, damp earth, deep peat smoke, and charcoal, followed by another wave of fruit (this time, dried fruit), finishing off with subtle charred oak and roasted nuts. This whisky is better than White Bowmore, and it falls just short of Black Bowmore (which I rated 97), because it’s just a bit softer and less vibrant on the palate.',\n",
       " \"Definitely showing its age, but not in a bad way — the distillery character is still there. Solid foundation of thick, chewy toffee, old pot still rum, and fig cake. Fruity too, with notes of golden raisin and nectarine. Soft, seductive peat smoke, juicy oak, cinnamon, and brine round out the palate. Excellent balance! One of the finest Bowmore whiskies I’ve ever tasted (and, at this price, will probably never taste again.) (Editor's Pick) \",\n",
       " 'The Dalmore is one of a handful of whiskies that seem to be able to age in the cask for many decades and still improve. This one is incredibly viscous on the nose and palate (and very heavy on the tongue), with chewy toffee and old pot still rum. The classic Dalmore marmalade note shines throughout, along with vanilla cream, an array of dried spices (especially cinnamon and evergreen), juicy oak, forest bedding, rancio, old armagnac, polished leather, tobacco, maple syrup, dark chocolate, almond macaroon, and subtle espresso. Long, mouth-coating finish. The flavors evolve like waves lapping on the palate -- especially the interplay with the oak. I can’t drink this whisky slowly enough. A rare experience for the lucky few who can afford it. (Price is per 100ml).',\n",
       " 'A rich amber color and elegantly oxidized notes greet you. There are luscious old fruits—pineapple, dried peach, apricot—and puffs of coal-like smokiness. In time, sweet spices (cumin especially) emerge. Superbly balanced. The palate, while fragile, still has real sweetness alongside a lick of treacle. It can take a drop of water, allowing richer, darker fruits to emerge. The finish is powerful, long, and resonant. Superb, not over-wooded, and a fair price for such a rarity.\\xa0£1,995']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сформируем общий словарь для обучения моделей из обучающей и тестовой выборки\n",
    "ML_df['text'].astype('U')\n",
    "vocab_list = ML_df['text'].tolist()\n",
    "vocab_list[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c776af56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество сформированных признаков - 9086\n"
     ]
    }
   ],
   "source": [
    "vocabVect = CountVectorizer()\n",
    "vocabVect.fit(vocab_list)\n",
    "corpusVocab = vocabVect.vocabulary_\n",
    "print('Количество сформированных признаков - {}'.format(len(corpusVocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28aab7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "powerful=6255\n",
      "and=747\n",
      "intense=4413\n",
      "caramels=1621\n",
      "dried=2783\n",
      "peats=5974\n",
      "elegant=2936\n",
      "cigar=1836\n",
      "smoke=7474\n"
     ]
    }
   ],
   "source": [
    "for i in list(corpusVocab)[1:10]:\n",
    "    print('{}={}'.format(i, corpusVocab[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4816faa7",
   "metadata": {},
   "source": [
    "# Векторизация текста на основе модели \"мешка слов\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a54a201",
   "metadata": {},
   "source": [
    "### Векторизация текста поддерживается библиотекой scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca875959",
   "metadata": {},
   "source": [
    "# Использование класса CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5444706",
   "metadata": {},
   "source": [
    "### Подсчитывает количество слов словаря, входящих в данный текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f0166ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = vocabVect.transform(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68a0b8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2247x9086 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 127980 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "649422d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "885f4d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9086"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Размер нулевой строки 无效行的尺寸\n",
    "len(test_features.todense()[0].getA1())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7190dadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Непустые значения нулевой строки非空 空字符串值\n",
    "[i for i in test_features.todense()[0].getA1() if i>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e81e3ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1882',\n",
       " '1890',\n",
       " '1898',\n",
       " '18th',\n",
       " '19',\n",
       " '190',\n",
       " '1905',\n",
       " '191',\n",
       " '1911',\n",
       " '1913',\n",
       " '192',\n",
       " '1920s',\n",
       " '1926',\n",
       " '1946',\n",
       " '195',\n",
       " '1952',\n",
       " '1957',\n",
       " '1958',\n",
       " '1959',\n",
       " '196']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabVect.get_feature_names()[100:120]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563a61e2",
   "metadata": {},
   "source": [
    "# Использование класса TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8d42e3",
   "metadata": {},
   "source": [
    "### Вычисляет специфичность текста в корпусе текстов на основе метрики TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fc22d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2247x198463 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 434149 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfv = TfidfVectorizer(ngram_range=(1,3))\n",
    "tfidf_ngram_features = tfidfv.fit_transform(vocab_list)\n",
    "tfidf_ngram_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbe2efe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_ngram_features.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6091368b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198463"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Размер нулевой строки\n",
    "len(tfidf_ngram_features.todense()[0].getA1())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20df2380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.0255003110670377,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.04175285254572138,\n",
       " 0.07628985092230442,\n",
       " 0.07628985092230442,\n",
       " 0.07046662317041068,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.07207067819547541,\n",
       " 0.07207067819547541,\n",
       " 0.046069805214705065,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.03435665518498105,\n",
       " 0.07628985092230442,\n",
       " 0.08350257433898073,\n",
       " 0.06325389975373437,\n",
       " 0.06325389975373437,\n",
       " 0.08350257433898073,\n",
       " 0.06485795477879912,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.07928340161215172,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.060076171507098944,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.04980166266227114,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.11710130178969018,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.05903472702690536,\n",
       " 0.05433147816801608,\n",
       " 0.07396787261382436,\n",
       " 0.08350257433898073,\n",
       " 0.05855065089484509,\n",
       " 0.07207067819547541,\n",
       " 0.08350257433898073,\n",
       " 0.060638782051970104,\n",
       " 0.07396787261382436,\n",
       " 0.07628985092230442,\n",
       " 0.06402504954862172,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.0315733290249827,\n",
       " 0.07928340161215172,\n",
       " 0.08350257433898073,\n",
       " 0.031089252892922428,\n",
       " 0.06907712750562812,\n",
       " 0.07928340161215172,\n",
       " 0.06675514919714805,\n",
       " 0.0678515054686464,\n",
       " 0.04811052963696644,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.05207275695588711,\n",
       " 0.07396787261382436,\n",
       " 0.07928340161215172,\n",
       " 0.05722044747199168,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.015230061878907457,\n",
       " 0.049015949169688725,\n",
       " 0.08350257433898073,\n",
       " 0.023593248691283,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.025093708705215365,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.027936448634980158,\n",
       " 0.07207067819547541,\n",
       " 0.08350257433898073,\n",
       " 0.047769326600241975,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.07928340161215172,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.04793852968286073,\n",
       " 0.06485795477879912,\n",
       " 0.08350257433898073,\n",
       " 0.035325331814054436,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.07207067819547541,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.03514861345583591,\n",
       " 0.07046662317041068,\n",
       " 0.08350257433898073,\n",
       " 0.05722044747199168,\n",
       " 0.07928340161215172,\n",
       " 0.04355015387341296,\n",
       " 0.07928340161215172,\n",
       " 0.029408260287752237,\n",
       " 0.07928340161215172,\n",
       " 0.08350257433898073,\n",
       " 0.042588939245594835,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.07046662317041068,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.07628985092230442,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.06253597647031904,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.07628985092230442,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.047602830883400046,\n",
       " 0.07928340161215172,\n",
       " 0.08350257433898073,\n",
       " 0.06907712750562812,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.05433147816801608,\n",
       " 0.06675514919714805,\n",
       " 0.08350257433898073,\n",
       " 0.03330200542344097,\n",
       " 0.06485795477879912,\n",
       " 0.08350257433898073,\n",
       " 0.05498205001691828,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.12650779950746874,\n",
       " 0.07396787261382436,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.04565072467374634,\n",
       " 0.07928340161215172,\n",
       " 0.08350257433898073,\n",
       " 0.07679852631193504,\n",
       " 0.07628985092230442,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.06325389975373437,\n",
       " 0.08350257433898073,\n",
       " 0.029699757228139882,\n",
       " 0.04551469972627503,\n",
       " 0.08350257433898073,\n",
       " 0.06402504954862172,\n",
       " 0.0678515054686464,\n",
       " 0.08350257433898073,\n",
       " 0.04811052963696644,\n",
       " 0.06186440408895182,\n",
       " 0.08350257433898073,\n",
       " 0.03372853071769374,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.017281462463815973,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.04400762359797212,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.020723725218303856,\n",
       " 0.08350257433898073,\n",
       " 0.08350257433898073,\n",
       " 0.011896257756306476,\n",
       " 0.07928340161215172,\n",
       " 0.07928340161215172]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Непустые значения нулевой строки\n",
    "[i for i in tfidf_ngram_features.todense()[0].getA1() if i>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1471a78",
   "metadata": {},
   "source": [
    "# Решение задачи анализа тональности текста на основе модели \"мешка слов\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31200af",
   "metadata": {},
   "source": [
    "### С использованием кросс-валидации попробуем применить к корпусу текстов различные варианты векторизации и классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e123307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VectorizeAndClassify(vectorizers_list, classifiers_list):\n",
    "    for v in vectorizers_list:\n",
    "        for c in classifiers_list:\n",
    "            pipeline1 = Pipeline([(\"vectorizer\", v), (\"classifier\", c)])\n",
    "            score = cross_val_score(pipeline1, ML_df['text'], ML_df['value'], scoring='accuracy', cv=3).mean()\n",
    "            print('Векторизация - {}'.format(v))\n",
    "            print('Модель для классификации - {}'.format(c))\n",
    "            print('Accuracy = {}'.format(score))\n",
    "            print('===========================')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2cde64",
   "metadata": {},
   "source": [
    "### По варианту используем классификаторы \"LogisticRegression\" и \"Multinomial Naive Bayes - MNB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97207f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "splits = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "157d2dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "E:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Векторизация - CountVectorizer(vocabulary={'00': 0, '000': 1, '002': 2, '011': 3, '060': 4,\n",
      "                            '076': 5, '08': 6, '080': 7, '090': 8, '10': 9,\n",
      "                            '100': 10, '10042': 11, '100ml': 12, '101': 13,\n",
      "                            '1013': 14, '1014': 15, '101751': 16, '102': 17,\n",
      "                            '10206': 18, '10227': 19, '10229': 20, '103': 21,\n",
      "                            '10328': 22, '10439': 23, '105': 24, '106': 25,\n",
      "                            '10699': 26, '107': 27, '10804': 28, '10897': 29, ...})\n",
      "Модель для классификации - LogisticRegression(C=3.0)\n",
      "Accuracy = 0.11170449488206498\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Векторизация - CountVectorizer(vocabulary={'00': 0, '000': 1, '002': 2, '011': 3, '060': 4,\n",
      "                            '076': 5, '08': 6, '080': 7, '090': 8, '10': 9,\n",
      "                            '100': 10, '10042': 11, '100ml': 12, '101': 13,\n",
      "                            '1013': 14, '1014': 15, '101751': 16, '102': 17,\n",
      "                            '10206': 18, '10227': 19, '10229': 20, '103': 21,\n",
      "                            '10328': 22, '10439': 23, '105': 24, '106': 25,\n",
      "                            '10699': 26, '107': 27, '10804': 28, '10897': 29, ...})\n",
      "Модель для классификации - MultinomialNB()\n",
      "Accuracy = 0.10769915442812639\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "E:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Векторизация - TfidfVectorizer(vocabulary={'00': 0, '000': 1, '002': 2, '011': 3, '060': 4,\n",
      "                            '076': 5, '08': 6, '080': 7, '090': 8, '10': 9,\n",
      "                            '100': 10, '10042': 11, '100ml': 12, '101': 13,\n",
      "                            '1013': 14, '1014': 15, '101751': 16, '102': 17,\n",
      "                            '10206': 18, '10227': 19, '10229': 20, '103': 21,\n",
      "                            '10328': 22, '10439': 23, '105': 24, '106': 25,\n",
      "                            '10699': 26, '107': 27, '10804': 28, '10897': 29, ...})\n",
      "Модель для классификации - LogisticRegression(C=3.0)\n",
      "Accuracy = 0.11214953271028037\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Векторизация - TfidfVectorizer(vocabulary={'00': 0, '000': 1, '002': 2, '011': 3, '060': 4,\n",
      "                            '076': 5, '08': 6, '080': 7, '090': 8, '10': 9,\n",
      "                            '100': 10, '10042': 11, '100ml': 12, '101': 13,\n",
      "                            '1013': 14, '1014': 15, '101751': 16, '102': 17,\n",
      "                            '10206': 18, '10227': 19, '10229': 20, '103': 21,\n",
      "                            '10328': 22, '10439': 23, '105': 24, '106': 25,\n",
      "                            '10699': 26, '107': 27, '10804': 28, '10897': 29, ...})\n",
      "Модель для классификации - MultinomialNB()\n",
      "Accuracy = 0.1010235870048954\n",
      "===========================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "vectorizers_list = [CountVectorizer(vocabulary = corpusVocab), TfidfVectorizer(vocabulary = corpusVocab)]\n",
    "classifiers_list = [LogisticRegression(C=3.0), MultinomialNB()]\n",
    "VectorizeAndClassify(vectorizers_list, classifiers_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab3ef90",
   "metadata": {},
   "source": [
    "# Разделим выборку на обучающую и тестовую и проверим решение для лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "309e409f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(ML_df['text'], ML_df['value'], test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b94139e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(v, c):\n",
    "    model = Pipeline(\n",
    "        [(\"vectorizer\", v), \n",
    "         (\"classifier\", c)])\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print_accuracy_score_for_classes(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9fd73e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метка \t Accuracy\n",
      "70 \t 0.0\n",
      "72 \t 0.0\n",
      "73 \t 0.0\n",
      "74 \t 0.0\n",
      "76 \t 0.0\n",
      "77 \t 0.0\n",
      "78 \t 0.0\n",
      "79 \t 0.0\n",
      "80 \t 0.05\n",
      "81 \t 0.0\n",
      "82 \t 0.0\n",
      "83 \t 0.014285714285714285\n",
      "84 \t 0.15853658536585366\n",
      "85 \t 0.1782178217821782\n",
      "86 \t 0.12396694214876033\n",
      "87 \t 0.18181818181818182\n",
      "88 \t 0.20833333333333334\n",
      "89 \t 0.05660377358490566\n",
      "90 \t 0.0989010989010989\n",
      "91 \t 0.018867924528301886\n",
      "92 \t 0.0\n",
      "93 \t 0.0\n",
      "94 \t 0.0\n",
      "95 \t 0.0\n",
      "96 \t 0.0\n",
      "97 \t 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "sentiment(TfidfVectorizer(), LogisticRegression(C=3.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb541e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метка \t Accuracy\n",
      "70 \t 0.0\n",
      "72 \t 0.0\n",
      "73 \t 0.0\n",
      "74 \t 0.0\n",
      "76 \t 0.0\n",
      "77 \t 0.0\n",
      "78 \t 0.0\n",
      "79 \t 0.058823529411764705\n",
      "80 \t 0.05\n",
      "81 \t 0.027777777777777776\n",
      "82 \t 0.06382978723404255\n",
      "83 \t 0.08571428571428572\n",
      "84 \t 0.0975609756097561\n",
      "85 \t 0.1485148514851485\n",
      "86 \t 0.14049586776859505\n",
      "87 \t 0.13636363636363635\n",
      "88 \t 0.14583333333333334\n",
      "89 \t 0.09433962264150944\n",
      "90 \t 0.12087912087912088\n",
      "91 \t 0.05660377358490566\n",
      "92 \t 0.018867924528301886\n",
      "93 \t 0.04878048780487805\n",
      "94 \t 0.0\n",
      "95 \t 0.0\n",
      "96 \t 0.0\n",
      "97 \t 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "sentiment(CountVectorizer(), LogisticRegression(C=3.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a1a9484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метка \t Accuracy\n",
      "70 \t 0.0\n",
      "72 \t 0.0\n",
      "73 \t 0.0\n",
      "74 \t 0.0\n",
      "76 \t 0.0\n",
      "77 \t 0.0\n",
      "78 \t 0.0\n",
      "79 \t 0.0\n",
      "80 \t 0.0\n",
      "81 \t 0.0\n",
      "82 \t 0.0\n",
      "83 \t 0.0\n",
      "84 \t 0.012195121951219513\n",
      "85 \t 0.12871287128712872\n",
      "86 \t 0.0743801652892562\n",
      "87 \t 0.4818181818181818\n",
      "88 \t 0.3541666666666667\n",
      "89 \t 0.009433962264150943\n",
      "90 \t 0.04395604395604396\n",
      "91 \t 0.0\n",
      "92 \t 0.0\n",
      "93 \t 0.0\n",
      "94 \t 0.0\n",
      "95 \t 0.0\n",
      "96 \t 0.0\n",
      "97 \t 0.0\n"
     ]
    }
   ],
   "source": [
    "sentiment(TfidfVectorizer(), MultinomialNB(alpha=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1223e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метка \t Accuracy\n",
      "70 \t 0.0\n",
      "72 \t 0.0\n",
      "73 \t 0.0\n",
      "74 \t 0.0\n",
      "76 \t 0.0\n",
      "77 \t 0.0\n",
      "78 \t 0.0\n",
      "79 \t 0.0\n",
      "80 \t 0.025\n",
      "81 \t 0.0\n",
      "82 \t 0.0\n",
      "83 \t 0.014285714285714285\n",
      "84 \t 0.12195121951219512\n",
      "85 \t 0.22772277227722773\n",
      "86 \t 0.15702479338842976\n",
      "87 \t 0.2\n",
      "88 \t 0.28125\n",
      "89 \t 0.05660377358490566\n",
      "90 \t 0.08791208791208792\n",
      "91 \t 0.018867924528301886\n",
      "92 \t 0.018867924528301886\n",
      "93 \t 0.0\n",
      "94 \t 0.0\n",
      "95 \t 0.0\n",
      "96 \t 0.0\n",
      "97 \t 0.0\n"
     ]
    }
   ],
   "source": [
    "sentiment(CountVectorizer(), MultinomialNB(alpha=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964c47b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
